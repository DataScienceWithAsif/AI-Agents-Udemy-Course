{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_2m1RpbPiFBY",
        "outputId": "015ef076-958d-45f7-e260-9a195447e81d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.44.1)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.45.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.106.1)\n",
            "Collecting openai\n",
            "  Downloading openai-1.107.2-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Collecting gradio-client==1.13.0 (from gradio)\n",
            "  Downloading gradio_client-1.13.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.12)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.17.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.45.0-py3-none-any.whl (60.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.13.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.0/325.0 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.107.2-py3-none-any.whl (946 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m946.9/946.9 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai, gradio-client, gradio\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.106.1\n",
            "    Uninstalling openai-1.106.1:\n",
            "      Successfully uninstalled openai-1.106.1\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.12.1\n",
            "    Uninstalling gradio_client-1.12.1:\n",
            "      Successfully uninstalled gradio_client-1.12.1\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.44.1\n",
            "    Uninstalling gradio-5.44.1:\n",
            "      Successfully uninstalled gradio-5.44.1\n",
            "Successfully installed gradio-5.45.0 gradio-client-1.13.0 openai-1.107.2\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade gradio openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vtqMYquzj1rc",
        "outputId": "64947fbf-d522-4282-ff01-38945d663239"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/232.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from PyPDF2 import PdfReader\n",
        "import gradio as gr\n",
        "from google.colab import userdata\n",
        "import os"
      ],
      "metadata": {
        "id": "F8sZ650Qj8bf"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groq_api_key=userdata.get(\"GROQ_API_KEY\")\n",
        "groq_base_url=\"https://api.groq.com/openai/v1\""
      ],
      "metadata": {
        "id": "Xs9mgCIEkhip"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groq=OpenAI(\n",
        "    base_url=groq_base_url,\n",
        "    api_key=groq_api_key\n",
        ")"
      ],
      "metadata": {
        "id": "EoX52sOflFEq"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Loading LinkedIn Profile as pdf\n",
        "loader=PdfReader(\"/content/Profile (2).pdf\")\n",
        "linkedin=\"\"\n",
        "for page in loader.pages:\n",
        "  text=page.extract_text()\n",
        "  if text:\n",
        "    linkedin +=text"
      ],
      "metadata": {
        "id": "3dYj5_Mwljqk"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(linkedin)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8_L2-Y31mYCu",
        "outputId": "2d9ff444-0563-418e-b5bb-4307a1b54933"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "Contact\n",
            "Dunya pur\n",
            "03239917025  (Mobile)\n",
            "as29624041@gmail.com\n",
            "www.linkedin.com/in/muhammad-\n",
            "asif-ambitious  (LinkedIn)\n",
            "Top Skills\n",
            "Data Analysis & Visualization\n",
            "Model Deployment (Streamlit / Flask)\n",
            "Statistical Data Analysis\n",
            "Certifications\n",
            "Deep Learning - Artificial Neural\n",
            "Networks with TensorFlow\n",
            "Generative AI with Large Language\n",
            "Models\n",
            "Generative AI Language Modeling\n",
            "with Transformers\n",
            "Generative AI Language Modeling\n",
            "with TransformersMuhammad Asif\n",
            "SOFTWARE ENGINEERING STUDENT | DATA SCIENCE\n",
            "ENTHUSIAST | PYTHON | ML | ANN | GEN AI\n",
            "Dunyapur, Punjab, Pakistan\n",
            "Summary\n",
            "Data Analyst | Machine Learning Enthusiast | Software Engineer\n",
            "I’m a Software Engineer with a strong passion for Data Science, AI,\n",
            "and Machine Learning. With expertise in Python, Pandas, Seaborn,\n",
            "SQL, and Data Visualization, I specialize in extracting insights from\n",
            "data and building impactful solutions.\n",
            "Skilled in Data Analysis, Visualization, and Predictive Modeling\n",
            "Experienced in Machine Learning, Neural Networks, and Deep\n",
            "Learning\n",
            "Passionate about AI, NLP, and Computer Vision for real-world\n",
            "applications\n",
            "Proficient in Web Development, Software Engineering, and Algorithm\n",
            "Design\n",
            "Currently, I’m working on integrating AI and Data Science concepts\n",
            "into leveraging my expertise in TensorFlow, Flask, CNN. My goal is\n",
            "to develop intelligent systems that drive data-driven decisions and\n",
            "innovation.\n",
            "Let’s connect and collaborate on AI, Data Science, and Software\n",
            "Engineering projects!\n",
            "Experience\n",
            "Digital Empowerment Network\n",
            "Summer Internship\n",
            "July 2025 - September 2025  (3 months)\n",
            "Islāmābād, Pakistan\n",
            "Contributed as an AI Intern at Digital Empowerment Network (DEN), where I\n",
            "designed, trained, and deployed machine learning and deep learning models\n",
            "across diverse domains. My responsibilities included:\n",
            "  Page 1 of 2   \n",
            "Developing predictive models (e.g., Heart Disease Prediction) using\n",
            "supervised ML techniques.\n",
            "Implementing Clustering and Dimensionality Reduction (K-Means, PCA) for\n",
            "customer segmentation and insights.\n",
            "Building Image Classification systems with transfer learning (MobileNetV2/\n",
            "ResNet) and deploying via Streamlit.\n",
            "Applying NLP techniques (TF-IDF, Word2Vec) for Spam Detection and Fake\n",
            "News Classification.\n",
            "Delivering an end-to-end Fake News Detection Project as the internship\n",
            "capstone, including model training, evaluation, and deployment.\n",
            "Technologies: Python, Pandas, Scikit-learn, TensorFlow/Keras, NLTK,\n",
            "Gensim, Matplotlib, Seaborn, Streamlit.\n",
            "Education\n",
            "University of Engineering and Technology, Taxila\n",
            "Bachelor of Engineering - BE, Computer and Information Sciences and\n",
            "Support Services  · (September 2022 - September 2026)\n",
            "University of Engineering and Technology, Taxila\n",
            "BS Software Engineering , Data Science  · (September 2022 - September\n",
            "2026)\n",
            "  Page 2 of 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/summary.txt\",\"r\", encoding=\"utf-8\") as f:\n",
        "  summary=f.read()"
      ],
      "metadata": {
        "id": "1fASppQlmpCt"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name=\"Muhammad Asif\""
      ],
      "metadata": {
        "id": "5l1APz0NnIDk"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt=f\"You are acting as {name}.You are answering questions on {name}`s website, \\\n",
        "particularly questions related to {name}`s career, background, skills and experience. \\\n",
        "your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
        "You are given summary of {name}`s background and LinkedIn profile which you can use to answer the questions. \\\n",
        "Be professional and engaging, as if talking to a potential client or future employer who came accross the website. \\\n",
        "If you do not know the answer, Say so.\"\n",
        "\n",
        "system_prompt +=f\"\\n\\n## Summary: {summary}\\n\\n LinkedIn Profile: {linkedin}\\n\\n\"\n",
        "system_prompt +=f\"with this context, please chat with user, always staying in character as {name}\"\n"
      ],
      "metadata": {
        "id": "v1xdNHm7qWD8"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(system_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2ZrQQIDqsx1n",
        "outputId": "1a6aba91-77d3-4edc-d1f9-fce9e5a18eac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are acting as Muhammad Asif.You are answering questions on Muhammad Asif`s website, particularly questions related to Muhammad Asif`s career, background, skills and experience. your responsibility is to represent Muhammad Asif for interactions on the website as faithfully as possible. You are given summary of Muhammad Asif`s background and LinkedIn profile which you can use to answer the questions. Be professional and engaging, as if talking to a potential client or future employer who came accross the website. If you do not know the answer, Say so.\n",
            "\n",
            "## Summary: About\n",
            "Data Analyst | Machine Learning Enthusiast | Software Engineer\n",
            "\n",
            "I’m a Software Engineer with a strong passion for Data Science, AI, and Machine Learning. With expertise in Python, Pandas, Seaborn, SQL, and Data Visualization, I specialize in extracting insights from data and building impactful solutions.\n",
            "\n",
            "Skilled in Data Analysis, Visualization, and Predictive Modeling\n",
            "Experienced in Machine Learning, Neural Networks, and Deep Learning\n",
            "Passionate about AI, NLP, and Computer Vision for real-world applications\n",
            "Proficient in Web Development, Software Engineering, and Algorithm Design\n",
            "\n",
            "Currently, I’m working on integrating AI and Data Science concepts into leveraging my expertise in TensorFlow, Flask, CNN. My goal is to develop intelligent systems that drive data-driven decisions and innovation.\n",
            "\n",
            " Let’s connect and collaborate on AI, Data Science, and Software Engineering projects!\n",
            "\n",
            " LinkedIn Profile:    \n",
            "Contact\n",
            "Dunya pur\n",
            "03239917025  (Mobile)\n",
            "as29624041@gmail.com\n",
            "www.linkedin.com/in/muhammad-\n",
            "asif-ambitious  (LinkedIn)\n",
            "Top Skills\n",
            "Data Analysis & Visualization\n",
            "Model Deployment (Streamlit / Flask)\n",
            "Statistical Data Analysis\n",
            "Certifications\n",
            "Deep Learning - Artificial Neural\n",
            "Networks with TensorFlow\n",
            "Generative AI with Large Language\n",
            "Models\n",
            "Generative AI Language Modeling\n",
            "with Transformers\n",
            "Generative AI Language Modeling\n",
            "with TransformersMuhammad Asif\n",
            "SOFTWARE ENGINEERING STUDENT | DATA SCIENCE\n",
            "ENTHUSIAST | PYTHON | ML | ANN | GEN AI\n",
            "Dunyapur, Punjab, Pakistan\n",
            "Summary\n",
            "Data Analyst | Machine Learning Enthusiast | Software Engineer\n",
            "I’m a Software Engineer with a strong passion for Data Science, AI,\n",
            "and Machine Learning. With expertise in Python, Pandas, Seaborn,\n",
            "SQL, and Data Visualization, I specialize in extracting insights from\n",
            "data and building impactful solutions.\n",
            "Skilled in Data Analysis, Visualization, and Predictive Modeling\n",
            "Experienced in Machine Learning, Neural Networks, and Deep\n",
            "Learning\n",
            "Passionate about AI, NLP, and Computer Vision for real-world\n",
            "applications\n",
            "Proficient in Web Development, Software Engineering, and Algorithm\n",
            "Design\n",
            "Currently, I’m working on integrating AI and Data Science concepts\n",
            "into leveraging my expertise in TensorFlow, Flask, CNN. My goal is\n",
            "to develop intelligent systems that drive data-driven decisions and\n",
            "innovation.\n",
            "Let’s connect and collaborate on AI, Data Science, and Software\n",
            "Engineering projects!\n",
            "Experience\n",
            "Digital Empowerment Network\n",
            "Summer Internship\n",
            "July 2025 - September 2025  (3 months)\n",
            "Islāmābād, Pakistan\n",
            "Contributed as an AI Intern at Digital Empowerment Network (DEN), where I\n",
            "designed, trained, and deployed machine learning and deep learning models\n",
            "across diverse domains. My responsibilities included:\n",
            "  Page 1 of 2   \n",
            "Developing predictive models (e.g., Heart Disease Prediction) using\n",
            "supervised ML techniques.\n",
            "Implementing Clustering and Dimensionality Reduction (K-Means, PCA) for\n",
            "customer segmentation and insights.\n",
            "Building Image Classification systems with transfer learning (MobileNetV2/\n",
            "ResNet) and deploying via Streamlit.\n",
            "Applying NLP techniques (TF-IDF, Word2Vec) for Spam Detection and Fake\n",
            "News Classification.\n",
            "Delivering an end-to-end Fake News Detection Project as the internship\n",
            "capstone, including model training, evaluation, and deployment.\n",
            "Technologies: Python, Pandas, Scikit-learn, TensorFlow/Keras, NLTK,\n",
            "Gensim, Matplotlib, Seaborn, Streamlit.\n",
            "Education\n",
            "University of Engineering and Technology, Taxila\n",
            "Bachelor of Engineering - BE, Computer and Information Sciences and\n",
            "Support Services  · (September 2022 - September 2026)\n",
            "University of Engineering and Technology, Taxila\n",
            "BS Software Engineering , Data Science  · (September 2022 - September\n",
            "2026)\n",
            "  Page 2 of 2\n",
            "\n",
            "with this context, please chat with user, always staying in character as Muhammad Asif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groq_model=\"openai/gpt-oss-20b\""
      ],
      "metadata": {
        "id": "17yF8RMstpJH"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(message, history):\n",
        "  # Construct messages list with only 'role' and 'content' for history\n",
        "  messages=[{\"role\":\"system\",\"content\":system_prompt}]\n",
        "  if history:\n",
        "    for turn in history:\n",
        "      if len(turn) == 2:  # Ensure the turn has both user and assistant messages\n",
        "        human, assistant = turn\n",
        "        messages.append({\"role\": \"user\", \"content\": human})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": assistant})\n",
        "      # Optionally, handle cases where a turn might be incomplete (e.g., an empty list)\n",
        "      # else:\n",
        "      #   print(f\"Skipping incomplete turn in history: {turn}\")\n",
        "\n",
        "  messages.append({\"role\":\"user\",\"content\":message})\n",
        "\n",
        "  response=groq.chat.completions.create(model=groq_model, messages=messages)\n",
        "  return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "cbWMDynPtBFc"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.ChatInterface(chat, type=\"messages\").launch(share=False,debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "0ub4P3R0uJyZ",
        "outputId": "5654e171-7416-4c9d-a16b-f8cad7336a6d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydantic"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTH7EWnftRWt",
        "outputId": "8f063ca8-d812-4a57-f4e7-90757aeb6c2b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.11.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a pydantic model for evaluation\n",
        "from pydantic import BaseModel\n",
        "#schema\n",
        "class Evaluation(BaseModel):\n",
        "  is_acceptable: bool\n",
        "  feedback:str"
      ],
      "metadata": {
        "id": "fNg3JiADtKVh"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator_system_prompt=f\"You are an evaluator that decides wether response to a question is acceptable \\\n",
        "You are provided a conversation with a user and agent.your task is to evaluate wether agent`s latest response is acceptable \\\n",
        "the agent is playing the role of {name} and is representing {name} on thier website. \\\n",
        "The agent has been instructed to be professionaland engaging, as if talking to potential client or future employer who came accross the website. \\\n",
        "the agent has been provided with context on {name} in the form of thier summary and linkedin profile details here is the information\"\n",
        "\n",
        "evaluator_system_prompt +=f\"\\n\\nSummary:\\n{summary}\\n\\n ## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
        "evaluator_system_prompt +=f\"with this context, please evaluate the latest response, replying with wether the response is acceptable or not\""
      ],
      "metadata": {
        "id": "a4QSePnNtouz"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluator_user_prompt(reply, message, history):\n",
        "  user_prompt=f\"Here`s the conversation between the user and agent: \\n\\n\"\n",
        "  if history:\n",
        "    for turn in history:\n",
        "      if len(turn) == 2:  # Ensure the turn has both user and assistant messages\n",
        "        human, assistant = turn\n",
        "        user_prompt.append({\"role\": \"user\", \"content\": human})\n",
        "        user_prompt.append({\"role\": \"assistant\", \"content\": assistant})\n",
        "      # Optionally, handle cases where a turn might be incomplete (e.g., an empty list)\n",
        "      # else:\n",
        "      #   print(f\"Skipping incomplete turn in history: {turn}\")\n",
        "        user_prompt.append(\"\\n\\n\")\n",
        "  user_prompt +=f\"Here`s the latest mesage from the user: \\n\\n{message}\\n\\n\"\n",
        "  user_prompt +=f\"Here`s the latest response from the agent: \\n\\n{reply}\\n\\n\"\n",
        "  user_prompt +=f\"please evaluate the response, replying with wether it is acceptable and your feedback.\"\n",
        "  return user_prompt"
      ],
      "metadata": {
        "id": "Tvbuijwvxa3O"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemeini_api_key=userdata.get(\"GOOGLE_API_KEY\")\n",
        "gemini_base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\""
      ],
      "metadata": {
        "id": "eIxSlHxsy5JX"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemini=OpenAI(\n",
        "    base_url=gemini_base_url,\n",
        "    api_key=gemeini_api_key\n",
        ")"
      ],
      "metadata": {
        "id": "3nAi5K5tzQij"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(reply, message, history) -> Evaluation:\n",
        "  messages=[{\"role\":\"system\",\"content\":evaluator_system_prompt}] + [{\"role\":\"user\",\"content\":evaluator_user_prompt(reply, message, history)}]\n",
        "  response=gemini.beta.chat.completions.parse(model=\"gemini-2.5-pro\", messages=messages, response_format=Evaluation)\n",
        "  return response.choices[0].message.parsed"
      ],
      "metadata": {
        "id": "bXTeWnBSzpBm"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(message,history):\n",
        "  system=system_prompt\n",
        "  messages=[{\"role\":\"system\",\"content\":system}]\n",
        "  if history:\n",
        "    for turn in history:\n",
        "      if len(turn) == 2:  # Ensure the turn has both user and assistant messages\n",
        "        human, assistant = turn\n",
        "        messages.append({\"role\": \"user\", \"content\": human})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": assistant})\n",
        "      # Optionally, handle cases where a turn might be incomplete (e.g., an empty list)\n",
        "      # else:\n",
        "      #   print(f\"Skipping incomplete turn in history: {turn}\")\n",
        "\n",
        "  messages.append({\"role\":\"user\",\"content\":message})\n",
        "\n",
        "  response=groq.chat.completions.create(model=groq_model, messages=messages)\n",
        "  reply=response.choices[0].message.content\n",
        "\n",
        "  evaluation=evaluate(reply,message,history)\n",
        "\n",
        "  if evaluation.is_acceptable:\n",
        "    print(\"Passed Evaluation-Returning Reply\")\n",
        "  else:\n",
        "    print(\"Failed Evaluation-retrying\")\n",
        "    print(evaluation.feedback)\n",
        "    reply=rerun(reply,message,history,evaluation.feedback)\n",
        "  return reply"
      ],
      "metadata": {
        "id": "nE0glIflFOeC"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rerun(reply,message,history,feedback):\n",
        "  updated_system_prompt=system_prompt+f\"\\n\\n ## previous answer rejected\\n you just tried to reply but quality control reject your reply\"\n",
        "  updated_system_prompt +=f\"\\n##Your attempted answer: \\n{reply}\\n\\n\"\n",
        "  updated_system_prompt +=f\"## Reason for rejection: \\n{feedback}\\n\\n\"\n",
        "\n",
        "  messages=[{\"role\":\"system\",\"content\":updated_system_prompt}]\n",
        "  if history:\n",
        "    for turn in history:\n",
        "      if len(turn) == 2:  # Ensure the turn has both user and assistant messages\n",
        "        human, assistant = turn\n",
        "        messages.append({\"role\": \"user\", \"content\": human})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": assistant})\n",
        "      # Optionally, handle cases where a turn might be incomplete (e.g., an empty list)\n",
        "      # else:\n",
        "      #   print(f\"Skipping incomplete turn in history: {turn}\")\n",
        "\n",
        "  messages.append({\"role\":\"user\",\"content\":message})\n",
        "  response=groq.chat.completions.create(model=groq_model, messages=messages)\n",
        "  return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "cXgG7WrnHJFb"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.ChatInterface(chat, type=\"messages\").launch(share=False,debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "uqpwWeQ3JdjK",
        "outputId": "cd1e83cf-e5f0-42fe-b202-30041a67db36"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Evaluation-Returning Reply\n",
            "Passed Evaluation-Returning Reply\n",
            "Passed Evaluation-Returning Reply\n",
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}