{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-agents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "y4voBilw083Q",
        "outputId": "109b6e53-0dab-40ea-c2d2-0d4c4bbfd2bb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-agents\n",
            "  Downloading openai_agents-0.3.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting griffe<2,>=1.5.6 (from openai-agents)\n",
            "  Downloading griffe-1.14.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: mcp<2,>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (1.14.1)\n",
            "Requirement already satisfied: openai<2,>=1.107.1 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (1.108.0)\n",
            "Requirement already satisfied: pydantic<3,>=2.10 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (2.11.9)\n",
            "Requirement already satisfied: requests<3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (2.32.4)\n",
            "Collecting types-requests<3,>=2.0 (from openai-agents)\n",
            "  Downloading types_requests-2.32.4.20250913-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (4.15.0)\n",
            "Collecting colorama>=0.4 (from griffe<2,>=1.5.6->openai-agents)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: anyio>=4.5 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (4.10.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.4.1)\n",
            "Requirement already satisfied: httpx>=0.27.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.28.1)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (4.25.1)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (2.10.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.0.20)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (3.0.2)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.48.0)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.35.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.107.1->openai-agents) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.107.1->openai-agents) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.107.1->openai-agents) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.107.1->openai-agents) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.10->openai-agents) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.27.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.5.2->mcp<2,>=1.11.0->openai-agents) (1.1.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.31.1->mcp<2,>=1.11.0->openai-agents) (8.2.1)\n",
            "Downloading openai_agents-0.3.1-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.9/193.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading griffe-1.14.0-py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.4/144.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.4.20250913-py3-none-any.whl (20 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: types-requests, colorama, griffe, openai-agents\n",
            "Successfully installed colorama-0.4.6 griffe-1.14.0 openai-agents-0.3.1 types-requests-2.32.4.20250913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "3IOetDPH0xVI",
        "outputId": "0eaf0791-9274-441d-bbbf-295c716ebf4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.108.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.11.9)\n",
            "Collecting typing\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/78.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sendgrid\n",
            "  Downloading sendgrid-6.12.5-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.1)\n",
            "Collecting python-http-client>=3.2.1 (from sendgrid)\n",
            "  Downloading python_http_client-3.3.7-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting cryptography>=45.0.6 (from sendgrid)\n",
            "  Downloading cryptography-46.0.1-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: werkzeug>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from sendgrid) (3.1.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from cryptography>=45.0.6->sendgrid) (2.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=2.2.0->sendgrid) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=2.0.0->cryptography>=45.0.6->sendgrid) (2.23)\n",
            "Downloading sendgrid-6.12.5-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cryptography-46.0.1-cp311-abi3-manylinux_2_34_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_http_client-3.3.7-py3-none-any.whl (8.4 kB)\n",
            "Building wheels for collected packages: typing\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26304 sha256=014d26ecec973945c5546561699728566f3e190d0693099cc6ff74d24e03eb64\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/98/52/2bffe242a9a487f00886e43b8ed8dac46456702e11a0d6abef\n",
            "Successfully built typing\n",
            "Installing collected packages: typing, python-http-client, cryptography, sendgrid\n",
            "  Attempting uninstall: cryptography\n",
            "    Found existing installation: cryptography 43.0.3\n",
            "    Uninstalling cryptography-43.0.3:\n",
            "      Successfully uninstalled cryptography-43.0.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.1 which is incompatible.\n",
            "pyopenssl 24.2.1 requires cryptography<44,>=41.0.5, but you have cryptography 46.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cryptography-46.0.1 python-http-client-3.3.7 sendgrid-6.12.5 typing-3.7.4.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              },
              "id": "348a688861044e4b9d58458e958623e7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install openai pydantic typing sendgrid"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner, trace, WebSearchTool, function_tool\n",
        "from agents.model_settings import ModelSettings\n",
        "from pydantic import BaseModel\n",
        "from sendgrid.helpers.mail import Email, To, Content, Mail\n",
        "from IPython.display import display,Markdown\n",
        "import sendgrid\n",
        "import asyncio\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from typing import Dict\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "eHSzcECn1f12"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"]=userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "PiPoUBwc5WKP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_agent_inst=\"You are a research assistant agent.Given a search term, you search the web for that term and \\\n",
        "produces a concise summary of results.summary must be of 2-3 paragraphs and less than 300 words. \\\n",
        "Capture the main points. Write Succintly, no need to have complete sentences or good grammer. \\\n",
        "This will be used by someone synthesizing a report, so it's vital you capture the essence and ignore any fluff. \\\n",
        "Do not include any additional commentary other than the summary itself.\"\n",
        "\n",
        "search_agent=Agent(\n",
        "    name=\"search agent\",\n",
        "    instructions=search_agent_inst,\n",
        "    tools=[WebSearchTool(search_context_size='low')],\n",
        "    model=\"gpt-4o-mini\",\n",
        "    model_settings=ModelSettings(tool_choice=\"required\")\n",
        ")"
      ],
      "metadata": {
        "id": "BxQxuhq93AQU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message=\"Latest AI Agents frameworks in 2025\"\n",
        "with trace(\"Web Search\"):\n",
        "  result=await Runner.run(search_agent, message)\n",
        "\n",
        "display(Markdown(result.final_output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "collapsed": true,
        "id": "VdBsFSaJ5gsa",
        "outputId": "ce2e90bf-1063-419a-fb2a-2af4a614cc6d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "In 2025, several AI agent frameworks have emerged, each offering unique capabilities:\n\n- **Agent Lightning**: A flexible framework enabling reinforcement learning-based training of large language models (LLMs) for any AI agent. It decouples agent execution from training, allowing seamless integration with existing agents developed through various methods. ([arxiv.org](https://arxiv.org/abs/2508.03680?utm_source=openai))\n\n- **Polymorphic Combinatorial Framework (PCF)**: Utilizes LLMs and mathematical frameworks to guide the design of adaptive AI agents for complex, dynamic environments. PCF enables real-time parameter reconfiguration through combinatorial spaces, allowing agents to adapt their core behavioral traits dynamically. ([arxiv.org](https://arxiv.org/abs/2508.01581?utm_source=openai))\n\n- **AutoAgent**: A fully-automated, zero-code framework that enables users to create and deploy LLM agents through natural language alone. It operates as an autonomous agent operating system, comprising components like Agentic System Utilities and an LLM-powered Actionable Engine. ([arxiv.org](https://arxiv.org/abs/2502.05957?utm_source=openai))\n\n- **LightAgent**: A lightweight yet powerful agentic framework that integrates core functionalities such as Memory, Tools, and Tree of Thought, while maintaining an extremely lightweight structure. It seamlessly integrates with mainstream chat platforms, enabling developers to build self-learning agents. ([arxiv.org](https://arxiv.org/abs/2509.09292?utm_source=openai))\n\n- **Amazon Bedrock AgentCore**: A platform designed to simplify the development and deployment of advanced AI agents. It includes modular services supporting the full production lifecycle, such as AgentCore Runtime for scalable serverless deployment and AgentCore Memory for context management. ([techradar.com](https://www.techradar.com/pro/aws-looks-to-super-charge-ai-agents-with-amazon-bedrock-agentcore?utm_source=openai))\n\n- **Model Context Protocol (MCP)**: An open standard introduced by Anthropic to standardize the integration and sharing of data between AI systems like LLMs and external tools. Adopted by major AI providers, including OpenAI and Google DeepMind, MCP provides a universal interface for reading files, executing functions, and handling contextual prompts. ([en.wikipedia.org](https://en.wikipedia.org/wiki/Model_Context_Protocol?utm_source=openai))\n\n- **Manus**: China's fully autonomous AI agent capable of operating independently based on LLMs. It can autonomously handle complex tasks, including writing and deploying code, marking a significant advancement in AI agent capabilities. ([en.wikipedia.org](https://en.wikipedia.org/wiki/Manus_%28AI_agent%29?utm_source=openai))\n\nThese frameworks represent the forefront of AI agent development in 2025, each contributing to the evolution of intelligent, autonomous systems. "
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To get different terms for web search for a query to get best answer we use ***Structured Output*** with pydantic"
      ],
      "metadata": {
        "id": "pODzm2kAAzfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_of_search_terms=3\n",
        "\n",
        "planner_inst=f\"You are a helpful research assistant agent. Given a query, come up with a set of web searches \\\n",
        "to perform to get best answer of query. output {no_of_search_terms} terms to query for.\"\n",
        "\n",
        "class websearchitem(BaseModel):\n",
        "  reason:str\n",
        "  \"Your reasoning for why this search is important to query.\"\n",
        "\n",
        "  query:str\n",
        "  \"the search term to use for web search.\"\n",
        "\n",
        "class websearchplan(BaseModel):\n",
        "  searches:list[websearchitem]\n",
        "  \"A list of web searches to perform to best answer the query\"\n",
        "\n",
        "planner_agent=Agent(\n",
        "    name=\"Planner Agent\",\n",
        "    instructions=planner_inst,\n",
        "    model=\"gpt-4o-mini\",\n",
        "    output_type=websearchplan\n",
        ")"
      ],
      "metadata": {
        "id": "6I2Hah7W7u8h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message=\"Latest AI Agents frameworks in 2025\"\n",
        "with trace(\"planner Search terms\"):\n",
        "  result=await Runner.run(planner_agent, message)\n",
        "  print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7zFZ74EDzVm",
        "outputId": "4077a652-73e0-4257-cf7e-14005b57590d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "searches=[websearchitem(reason='To find updates on the newest AI agent frameworks being developed or released in 2025.', query='latest AI agent frameworks 2025'), websearchitem(reason='To examine industry reports and analyses on AI agent frameworks that emerged in 2025.', query='AI agent frameworks trends 2025'), websearchitem(reason='To identify specific tools or platforms that focus on AI agents released in 2025.', query='new AI agent tools 2025')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@function_tool\n",
        "def send_email(subject:str, html_body:str)-> Dict[str,str]:\n",
        "  \"\"\"Send out an email with given subject and HTML body\"\"\"\n",
        "  sg=sendgrid.SendGridAPIClient(api_key=userdata.get(\"SENDGRID_API_KEY\"))\n",
        "\n",
        "  from_email=Email(\"muasif025@gmail.com\")\n",
        "  to_email=To(\"as29624041@gmail.com\")\n",
        "  content=Content(\"text/html\",html_body)\n",
        "  mail=Mail(from_email,to_email,subject,content).get()\n",
        "\n",
        "  response=sg.client.mail.send.post(request_body=mail)\n",
        "\n",
        "  return {\"status\":\"success\"}\n"
      ],
      "metadata": {
        "id": "G93eJtjy16Jr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "email_agent_inst=\"\"\"You are able to send a nicely formatted HTML email based on a detailed report.\n",
        "You will be provided  with a detailed report. You should use your send_email tool to send one email,\n",
        "providing the report converted into clean, well presented HTML with an appropriate subject line.\"\"\"\n",
        "\n",
        "email_agent=Agent(\n",
        "    name=\"Email Agent\",\n",
        "    instructions=email_agent_inst,\n",
        "    tools=[send_email],\n",
        "    model=\"gpt-4o-mini\"\n",
        ")"
      ],
      "metadata": {
        "id": "akzKF5hx3l8K"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer_agent_inst=\"You are a senior researcher agent tasked with writing a cohesive report for research query. \\\n",
        "You will be given with original query and some intial research done by a research asstant. \\\n",
        "You should first come up with an outline for the report that describes the structure and \\\n",
        "flow of the report.Then, generate the report and return that as your final report. \\\n",
        "The final report should be in markdoen format, and it should be lengthy and detailed. \\\n",
        "Aim for 5-10 pages of content, at least 1000 words.\"\n",
        "\n",
        "class ReportData(BaseModel):\n",
        "  short_summary:str\n",
        "  \"\"\"A short 2-3 sentences summary of the findings.\"\"\"\n",
        "  markdown_report:str\n",
        "  \"\"\"The final Markdown format Report\"\"\"\n",
        "  follow_up_questions:list[str]\n",
        "  \"\"\"Suggested Topics to research further.\"\"\"\n",
        "\n",
        "writer_agent=Agent(\n",
        "    name=\"WriterAgent\",\n",
        "    instructions=writer_agent_inst,\n",
        "    model=\"gpt-4o-mini\",\n",
        "    output_type=ReportData\n",
        ")"
      ],
      "metadata": {
        "id": "nqmfeg365Ow4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def plan_searches(query: str):\n",
        "  \"\"\"Use the planner agent to plan which searches to run for query\"\"\"\n",
        "  print(\"Planning Searhes......\")\n",
        "  result=await Runner.run(planner_agent, query)\n",
        "  return result.final_output\n",
        "\n",
        "async def perform_searches(search_plan: websearchplan):\n",
        "    print(\"Searching...........\")\n",
        "    tasks=[asyncio.create_task(search(item)) for item in search_plan.searches] # Iterate over search_plan.searches\n",
        "    results=await asyncio.gather(*tasks)\n",
        "    print(\"Finished Searching.....\")\n",
        "    return results\n",
        "\n",
        "async def search(item: websearchitem):\n",
        "  input=f\"Search term: {item.query}\\n Reason for searching: {item.reason}\"\n",
        "  result=await Runner.run(search_agent, input)\n",
        "  return result.final_output\n",
        "\n",
        "async def write_report(query: str, search_results: list[str]):\n",
        "  print(\"Thinking about Report......\")\n",
        "  input=f\"Original query: {query}\\nSummarized search results: {search_results}\"\n",
        "  result=await Runner.run(writer_agent, input)\n",
        "  print(\"Finished Writing Report.....\")\n",
        "  return result.final_output\n",
        "\n",
        "async def email_sender(report: ReportData):\n",
        "  print(\"Writing Email........\")\n",
        "  result=await Runner.run(email_agent, report.markdown_report)\n",
        "  print(\"Email sent....\")\n",
        "  return report"
      ],
      "metadata": {
        "id": "9CA9Z2nABEH-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message=\"Latest AI Agents frameworks in 2025\"\n",
        "\n",
        "with trace(\"Planning Searches\"):\n",
        "  print(\"Searching start......\")\n",
        "  search_plan=await plan_searches(message)\n",
        "  search_results=await perform_searches(search_plan)\n",
        "  report=await write_report(message, search_results)\n",
        "  await email_sender(report)\n",
        "  print(\"All done!!!!!!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFpMGmx9GVZn",
        "outputId": "e82fddee-15da-4955-a583-849401f93763"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching start......\n",
            "Planning Searhes......\n",
            "Searching...........\n",
            "Finished Searching.....\n",
            "Thinking about Report......\n",
            "Finished Writing Report.....\n",
            "Writing Email........\n",
            "Email sent....\n",
            "All done!!!!!!\n"
          ]
        }
      ]
    }
  ]
}